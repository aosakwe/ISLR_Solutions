---
title: "Ch4_Lab"
author: "Adrien Osakwe"
output: pdf_document
---

## Stock Market Data

Working with the *Smarket* data set in the ISLR2 package.
Looking to use data from 1250 days of stock indices to predict stock price direction.
 
``` {r Smarket, echo = TRUE}
library(ISLR2)
names(Smarket)
dim(Smarket)
summary(Smarket)

## Generate correlation matrix using the quantitative variables
cor(Smarket[,-9])
# A quick scan of the matrix indicates a correlation between the year and the
#Volume
attach(Smarket)
boxplot(Volume ~ Year)
```


## Logistic Regression

Using log regression to predict direction with lag[1:5] and volume

``` {r log-reg, echo = TRUE}
#Use glm() with family = binomial to cal log-reg 
glm.fits <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = 
                  Smarket, family = binomial)

summary(glm.fits)
#smallest p-value is for lag1. as b1 is negative, a positive return lag1 would
#predict and positive return today
summary(glm.fits)$coef

## Running predict() here requires us to set the type parameter to "response" to
# output a posterior probability
contrasts(Direction) #this informs us that the probability is for today being Up

glm.probs <- predict(glm.fits, type = "response")
glm.probs[1:10]
#Hm, it's all 50/50... de la poudre de perlinpinpin!

#Can then convert P(x|y) into labels based on their values
glm.pred <- rep("Down",1250)
glm.pred[glm.probs > 0.5] <- "Up"
#Plot predictions against training values
table(glm.pred,Direction)
#Calculate Model Accuracy for training data
train_error <- (145 + 507)/1250
#Or do
mean(glm.pred == Direction)
## ~50% accuracy on the training data... oh boy

##Creating a test data set
train <- ( Year < 2005)
Smarket.2005 <- Smarket[!train ,]
dim (Smarket.2005)
Direction.2005 <- Direction[!train]

#repeat log-red with data from before 2005
glm.fits1 <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = 
                  Smarket, family = binomial, subset = train)
glm.probs1 <- predict(glm.fits1, Smarket.2005, type = "response")
glm.pred1 <- rep("Down", 252)
glm.pred1[glm.probs1 > 0.5] <- "Up"
table(glm.pred1,Direction.2005)
mean(glm.pred1 == Direction.2005)
mean(glm.pred1 != Direction.2005)
#Model is worse than a guess 0o0


#Rebuild model using less parameters
#repeat log-red with data from before 2005
glm.fits2 <- glm(Direction ~ Lag1 + Lag2, data = 
                  Smarket, family = binomial, subset = train)
glm.probs2 <- predict(glm.fits2, Smarket.2005, type = "response")
glm.pred2 <- rep("Down", 252)
glm.pred2[glm.probs2 > 0.5] <- "Up"
table(glm.pred2,Direction.2005)
mean(glm.pred2 == Direction.2005)
# based on this confusion matrix one could develop a trading strategy 
# (don't necessarily need a perfect model, just need one that improves your 
#chances)
```


### Linear Discriminant Analysis

``` {r LDA, echo = TRUE}

##LDAs are fit with the lda function
library(MASS)
lda.fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
lda.fit
plot(lda.fit)

lda.pred <- predict(lda.fit, Smarket.2005)
names(lda.pred)
lda.class <- lda.pred$class
table(lda.class,Direction.2005)
mean(lda.class == Direction.2005)

#Can recreate the labels by applying a 50% threshold to the posterior 
#probabilities
## May want to change posterior threshold depending on what bias we see in test
#results. Too many FP? Could try increasing the threshold
```


### Quadratic Discriminant Analysis

``` {r QDA, echo = TRUE}
## Called with the qda() function

qda.fit <- qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
qda.fit

qda.class <- predict(qda.fit, Smarket.2005)$class
table(qda.class, Direction.2005)
#At first glance we would say that the model is good at predicting Ups However, there is a very high FP rate (almost 3/4 of true Downs are predicted to be Ups), which, given that this model would be used to recommend investments is not great..
mean(qda.class == Direction.2005)
#Since the overall accuracy is 60% it's still much better than the previous models but is still a concern in my opinion.
```


### Naive Bayes

``` {r NB, echo = TRUE}
#Need to load the *e1071* library which contains the Naive Bayes method for R
library(e1071)

nb.fit <- naiveBayes(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)

nb.fit


nb.class <- predict(nb.fit, Smarket.2005) 
table(nb.class, Direction.2005)
mean(nb.class == Direction.2005)
#can also generate the probabilities for each prediction
nb.pred <- predict(nb.fit, Smarket.2005, type = "raw")
nb.pred[1:5,]
```


## K-Nearest Neighbours


``` {r KNN, echo = TRUE}
#Performed by using the knn() function

#Need a matrix composed of predictors from training data (train.x)
#A matrix with predictors from data we are trying to predict (test.xt)
#A vector with class labels for train.x (train.Direction)
#K, the number of NN to use in classifier
library(class)
library(ISLR2)

#Setup test data
attach(Smarket)
train <- ( Year < 2005)
train.x <- cbind(Lag1,Lag2)[train,]
test.x <- cbind(Lag1,Lag2)[!train,]
train.Direction <- Direction[train]
Direction.2005 <- Direction[!train]
set.seed(1)
knn.pred <- knn(train.x,test.x, train.Direction, k = 1)
table(knn.pred,Direction.2005)
#50% accuracy with k = 1, not great
mean(knn.pred == Direction.2005)

#K = 3
knn.pred2 <- knn(train.x,test.x, train.Direction, k = 3)
table(knn.pred2,Direction.2005)
mean(knn.pred2 == Direction.2005)

##Overall the QDA model had the highest accuracy on this data set 
#could still change what parameters we use in the model later to see if this brings us above the 60%
```

KNN on the caravan data set

``` {r KNN2, echo = TRUE}
dim(Caravan)
attach(Caravan)
summary(Purchase)

#Scaling all the predictors to prevent any bias due to different magnitudes from affecting knn prediction
standardized.X <- scale(Caravan[,-86])

#Training subsets
test <- 1:1000
train.X1 <- standardized.X[-test,]
test.X1 <- standardized.X[test,]
train.Y1 <- Purchase[-test]
test.Y1 <- Purchase[test]

set.seed(1)
knn.pred3 <- knn(train.X1,test.X1,train.Y1, k = 1)
mean(test.Y1 != knn.pred3)


##The error rate looks good here, but because it is higher than the proportion of Yes in the training data, we could get a lower error rate by just predicting everything as No!
mean(test.Y1 != "No")

table(knn.pred3,test.Y1)
(9)/(66+9)
#12% success rate if you only sell insurance to people who are predicted to buy it
# double the odds of just asking everyone (6%)
knn.pred4 <- knn(train.X1,test.X1,train.Y1, k = 3)
table(knn.pred4,test.Y1)
5/24
#K = 3 improves this even more!
knn.pred5 <- knn(train.X1,test.X1,train.Y1, k = 5)
table(knn.pred5,test.Y1)
4/15
#Even higher! unfortunately this comes at the cost of only suggesting 15 candidate buyers...


##Trying with a logistic regression
glm.fits3 <- glm(Purchase ~ . , data = Caravan, subset = -test, family = binomial)
glm.probs3 <- predict(glm.fits3,Caravan[test,],type = "response")
glm.pred3 <- rep("No",1000)
glm.pred3[glm.probs3 > 0.5] <- "Yes"
table(glm.pred3,test.Y1)
#All yes predictions are wrong!
glm.pred4 <- rep("No",1000)
glm.pred4[glm.probs3 > 0.25] <- "Yes"
table(glm.pred4,test.Y1)
#Now have a 33% success rate which is the best we have seen so far
```


### Poisson Regression

``` {r PR, echo = TRUE}
attach(Bikeshare)
dim(Bikeshare)
names(Bikeshare)

#Testing linear regression
mod.lm <- lm(bikers ~ mnth + hr + workingday + temp + weathersit, data = Bikeshare)
summary(mod.lm)

#Changing data values for mnth and hr
contrasts(Bikeshare$hr) <- contr.sum(24)
contrasts(Bikeshare$mnth) <- contr.sum(12)
mod.lm2 <- lm(bikers ~ mnth + hr + workingday + temp + weathersit, data = Bikeshare)
summary(mod.lm2)

## Showing that both coding approaches do not change the model's predictions
all.equal(predict(mod.lm), predict(mod.lm2))

## Get month coefficients
coef.months <- c(coef(mod.lm2)[2:12], -sum(coef(mod.lm2[2:12])))
plot(coef.months, xlab = "Month", ylab = "Coefficient", xaxt = "n", col = "blue", pch = 19, type = "o")
axis(side = 1,at = 1:12, labels = c("J","F","M","A","M","J","J","A","S","O","N","D"))


## now fitting a poisson regression on the data instead

mod.pois <- glm(bikers ~ mnth + hr + workingday + temp + weathersit, data = Bikeshare, family = poisson)
summary(mod.pois)

coef.months2 <- c(coef(mod.pois)[2:12], -sum(coef(mod.pois[2:12])))
plot(coef.months2, xlab = "Month", ylab = "Coefficient", xaxt = "n", col = "blue", pch = 19, type = "o")
axis(side = 1,at = 1:12, labels = c("J","F","M","A","M","J","J","A","S","O","N","D"))

coef.hr <- c(coef(mod.pois)[13:35], -sum(coef(mod.pois[13:35])))
plot(coef.hr, xlab = "Hour", ylab = "Coefficient", col = "red", pch = 18, type = "o")


plot(predict(mod.lm2),predict(mod.pois, type = "response"))
abline(0,1,col = 2, lwd = 3)
```


### Lab is complete